<tool id="biobb_ml_recurrent_neural_network_ext" name="RecurrentNeuralNetwork" version="4.0.0" >
    <description>: Wrapper of the TensorFlow Keras LSTM method using Recurrent Neural Networks.</description>
    <requirements>
        <requirement type="package"
        version="4.0.0"
        >biobb_ml</requirement>
    </requirements>
    <command detect_errors="aggressive"><![CDATA[
        
          ln -f -s ${input_dataset_path} ${input_dataset_path}_`echo $$`.${input_dataset_path.ext};
        
        #if $config.sele == "option1":
            ln -s -f ${config.properties} ${config.properties}_`echo $$`.${config.properties.ext};
          #end if

        recurrent_neural_network

        #if $config.sele == "option1":
            --config ${config.properties}_`echo $$`.${config.properties.ext}
          #else if $config.sele == "option2":
            --config '${config.jsonstr}'
          #else if $config.sele == "option3":
            --config '__oc____dq__target__dq__:${properties.target},__dq__validation_size__dq__:${properties.validation_size},__dq__window_size__dq__:${properties.window_size},__dq__test_size__dq__:${properties.test_size},__dq__hidden_layers__dq__:${properties.hidden_layers},__dq__optimizer__dq__:__dq__${properties.optimizer}__dq__,__dq__learning_rate__dq__:${properties.learning_rate},__dq__batch_size__dq__:${properties.batch_size},__dq__max_epochs__dq__:${properties.max_epochs},__dq__normalize_cm__dq__:${properties.normalize_cm}__cc__'
          #end if
        
          #if str($input_dataset_path) != 'None':
            --input_dataset_path ${input_dataset_path}_`echo $$`.${input_dataset_path.ext}
          #end if
        
        
          --output_model_path $outname_output_model_path
        
          --output_test_table_path $outname_output_test_table_path
        
          --output_plot_path $outname_output_plot_path
        ;
        #if $config.sele == "option1":
            rm -f ${config.properties}_`echo $$`.${config.properties.ext};
          #end if
        
          rm -f ${input_dataset_path}_`echo $$`.${input_dataset_path.ext};
        
        
          if test -f $outname_output_model_path; then mv $outname_output_model_path $output_model_path; fi;
        
          if test -f $outname_output_test_table_path; then mv $outname_output_test_table_path $output_test_table_path; fi;
        
          if test -f $outname_output_plot_path; then mv $outname_output_plot_path $output_plot_path; fi;
        
    ]]>
    </command>
    <inputs>
        
          <param name="input_dataset_path" type="data" format="csv"  optional="False" label="input CSV file" help="Path to the input dataset. Format: [input].csv"/>
        
        
          <param name="outname_output_model_path" type="text" value="myrecurrent_neural_network.h5"
              optional="False" label="output H5 name"
              help="Path to the output model file Format: [output].h5 "/>
        
          <param name="outname_output_test_table_path" type="text" value="myrecurrent_neural_network.csv"
              optional="True" label="output CSV name"
              help="Path to the test table file Format: [output].csv "/>
        
          <param name="outname_output_plot_path" type="text" value="myrecurrent_neural_network.png"
              optional="True" label="output PNG name"
              help="Loss, accuracy and MSE plots Format: [output].png "/>
        
        <conditional name="config">
            <param name="sele" type="select" label="Take tool settings:" help="Select where tool settings are to be read from">
              <option value="option3">Manual Input</option>
              <option value="option1">from configuration file</option>
              <option value="option2">from JSON string</option>
            </param>
            <when value="option1">
              <param name="properties" type="data" format="yml,json" optional="false" label="Configuration file" help="File containing tool settings. See below for the syntax"/>
            </when>
            <when value="option2">
              <param name="jsonstr" type="text" value="{}" optional="false" label="JSON string" help="JSON string containing tool settings. See below for the syntax"/>
            </when>
            <when value="option3">
            </when>
          </conditional>
          <section name="properties" title="Properties Input">
            
              <param name="target" type="text" label="target" help="Dependent variable you want to predict from your dataset. You can specify either a column name or a column index. Formats: { &#34;column&#34;: &#34;column3&#34; } or { &#34;index&#34;: 21 }. In case of mulitple formats, the first one will be picked. (Json)" value="{}">
                  <sanitizer><valid initial="string.printable"/></sanitizer>
                </param>
            
              <param name="validation_size" type="float"
                  value="0.2"
                  
                  label="validation_size" help="Represents the proportion of the dataset to include in the validation split. It should be between 0.0 and 1.0." optional="false"/>
            
              <param name="window_size" type="integer"
                  value="5"
                  
                  label="window_size" help="Number of steps for each window of training model." optional="false"/>
            
              <param name="test_size" type="integer"
                  value="5"
                  
                  label="test_size" help="Represents the number of samples of the dataset to include in the test split." optional="false"/>
            
              <param name="hidden_layers" type="text" label="hidden_layers" help="List of dictionaries with hidden layers values. Format: [ { &#39;size&#39;: 50, &#39;activation&#39;: &#39;relu&#39; } ]. (Json)" value="[]" >
                  <sanitizer><valid initial="string.printable"/></sanitizer>
                </param>
            
              <param name="optimizer" type="select" label="optimizer" help="Name of optimizer instance. " multiple="false">
                  
                    <option value="Adadelta"
                      
                    >Adadelta
                       - Adadelta optimization is a stochastic gradient descent method that is based on adaptive learning rate per dimension to address two drawbacks: the continual decay of learning rates throughout training and the need for a manually selected global learning rate
                    </option>
                  
                    <option value="Adagrad"
                      
                    >Adagrad
                       - Adagrad is an optimizer with parameter-specific learning rates; which are adapted relative to how frequently a parameter gets updated during training. The more updates a parameter receives; the smaller the updates
                    </option>
                  
                    <option value="Adam"
                      selected="true"
                    >Adam
                       - Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments
                    </option>
                  
                    <option value="Adamax"
                      
                    >Adamax
                       - It is a variant of Adam based on the infinity norm. Default parameters follow those provided in the paper. Adamax is sometimes superior to adam; specially in models with embeddings
                    </option>
                  
                    <option value="Ftrl"
                      
                    >Ftrl
                       - Optimizer that implements the FTRL algorithm
                    </option>
                  
                    <option value="Nadam"
                      
                    >Nadam
                       - Much like Adam is essentially RMSprop with momentum; Nadam is Adam with Nesterov momentum
                    </option>
                  
                    <option value="RMSprop"
                      
                    >RMSprop
                       - Optimizer that implements the RMSprop algorithm
                    </option>
                  
                    <option value="SGD"
                      
                    >SGD
                       - Gradient descent -with momentum- optimizer
                    </option>
                  
                </param>
            
              <param name="learning_rate" type="float"
                  value="0.02"
                  
                  label="learning_rate" help="Determines the step size at each iteration while moving toward a minimum of a loss function" optional="false"/>
            
              <param name="batch_size" type="integer"
                  value="100"
                  
                  label="batch_size" help="Number of samples per gradient update." optional="false"/>
            
              <param name="max_epochs" type="integer"
                  value="100"
                  
                  label="max_epochs" help="Number of epochs to train the model. As the early stopping is enabled, this is a maximum." optional="false"/>
            
              <param name="normalize_cm" type="boolean"
                  
                  label="normalize_cm" help="Whether or not to normalize the confusion matrix."
                />
            
          </section>
    </inputs>
    <outputs>
        
        
          <data name="output_model_path" format="h5" label="${outname_output_model_path}"/>
        
        
          <data name="output_test_table_path" format="csv" label="${outname_output_test_table_path}"/>
        
        
          <data name="output_plot_path" format="png" label="${outname_output_plot_path}"/>
        
    </outputs>
    <tests>
        <test>
        </test>
    </tests>
    <help>
.. class:: infomark

Check the syntax for the tool parameters at the original library documentation: https://biobb_ml.readthedocs.io/en/latest

-----

.. image:: http://mmb.irbbarcelona.org/biobb/assets/layouts/layout3/img/logo.png
    :width: 150

**https://mmb.irbbarcelona.org/biobb**

.. image:: https://bioexcel.eu/wp-content/uploads/2019/08/Bioexcel_logo_no_subheading_660px.png
        :width: 150

**https://bioexcel.eu**
   </help>

    <citations>
        <citation type="bibtex">
            @misc{githubbiobb,
            author = {Andrio P, Bayarri, G., Hospital A, Gelpi JL},
            year = {2019-21},
            title = {biobb: BioExcel building blocks },
            publisher = {GitHub},
            journal = {GitHub repository},
            url = {https://github.com/bioexcel/biobb_ml},
            }
        </citation>
        <citation type="doi">10.1038/s41597-019-0177-4</citation>
    </citations>
</tool>